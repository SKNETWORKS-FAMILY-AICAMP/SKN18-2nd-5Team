import warnings
warnings.filterwarnings('ignore')  # ê²½ê³  ë©”ì‹œì§€ ë¬´ì‹œ
import logging
logging.basicConfig(level=logging.INFO)  # ë©”ì¸íŒŒì¼ì—ì„œ 2ê°œì¤„ ë‹¤ ì“°ë©´ ë‹¤ë¥¸ íŒŒì¼ì—ì„œëŠ” ì²«ë²ˆì§¸ 
## ë¡œê¹… ë ˆë²¨ ì„¤ì •. ë¡œê¹…ì´ë€ ì½”ë“œ ì‹¤í–‰ ì¤‘ ë°œìƒí•˜ëŠ” ì´ë²¤íŠ¸ë¥¼ ê¸°ë¡í•˜ëŠ” ê²ƒ. print()ë³´ë‹¤ ê¹”ë”í•˜ê³  ë©”ëª¨ë¦¬ë‚­ë¹„ê°€ ì—†ìŒ. í˜„ì—…ì—ì„œ ë§ì´ ì‚¬ìš©í•¨.
## INFO : logging.info() ì¶œë ¥, ERROR : logging.info()ê°€ ì¶œë ¥ë˜ì§€ ì•Šê²Œ í•¨

import argparse # í„°ë¯¸ë„ì—ì„œ ì¸ìë¥¼ ì…ë ¥í•˜ëŠ”ëŒ€ë¡œ ì¶œë ¥í•˜ê²Œ í•˜ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬
import time
from datetime import datetime

##########
# ì½”ë“œ ì •ì˜ ì˜ì—­
##########
# import ë’¤ì—ëŠ” í•¨ìˆ˜ ë˜ëŠ” í´ë˜ìŠ¤ë§Œ ì‘ì„±
# from ë’¤ì—ëŠ” í´ë”.íŒŒì¼ëª… ì‘ì„±

from service.data_setup import do_load_dataset
from service.preprocessing.adata_preprocessing import do_preprocessing
from service.modeling.training import do_training
from service.modeling.model import Model_Type
# from service.submission import create_submission_file

def main(args):
    # ì „ì²´ ì‹¤í–‰ ì‹œì‘ ì‹œê°„
    total_start_time = time.time()
    
    logging.info("="*50)
    logging.info("ğŸ¨ í˜¸í…” ì˜ˆì•½ ì·¨ì†Œ ì˜ˆì¸¡ ëª¨ë¸ - ì „ì²´ ëª¨ë¸ ì‹¤í–‰ ì‹œì‘")
    logging.info(f"ì‹¤í–‰ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    logging.info("="*50)
    
    # 1. ë°ì´í„° ë¡œë“œ (í•œ ë²ˆë§Œ ìˆ˜í–‰)
    logging.info("ğŸ“Š ë°ì´í„° ë¡œë“œ ì‹œì‘...")
    data_start_time = time.time()
    x_tr, x_te, y_tr, y_te = do_load_dataset(
        train_path=args.path_train, test_path=args.path_test
        , target_name=args.target_name)
    data_time = time.time() - data_start_time
    logging.info(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ (ì†Œìš”ì‹œê°„: {data_time:.2f}ì´ˆ)")

    # 2. ë°ì´í„° ì „ì²˜ë¦¬ëŠ” ê° ëª¨ë¸ë³„ë¡œ ìˆ˜í–‰ (ëª¨ë¸ë³„ë¡œ ì¸ì½”ë”© ë°©ì‹ì´ ë‹¤ë¦„)
    logging.info("ğŸ”§ ëª¨ë¸ë³„ ë°ì´í„° ì „ì²˜ë¦¬ ë° í•™ìŠµ ì‹œì‘...")

    # 3. ë¹ ë¥¸ ëª¨ë¸ë“¤ë§Œ ì„ íƒí•´ì„œ ìˆœì°¨ ì‹¤í–‰
    fast_model_names = ['gradient_boosting', 'extra_trees', 'xgboost', 'random_forest', 
                       'lightgbm', 'logistic_regression', 'naive_bayes']
    successful_models = []
    failed_models = []
    
    logging.info(f"ğŸ¤– ì´ {len(fast_model_names)}ê°œ ë¹ ë¥¸ ëª¨ë¸ í•™ìŠµ ì‹œì‘...")
    logging.info("âš¡ ì‹¤í–‰ ëª¨ë¸: Gradient Boosting, Extra Trees, XGBoost, Random Forest, LightGBM, Logistic Regression, Naive Bayes")
    logging.info("-" * 50)
    
    for i, model_name in enumerate(fast_model_names, 1):
        try:
            logging.info(f"[{i}/{len(fast_model_names)}] {model_name.upper()} ëª¨ë¸ í•™ìŠµ ì‹œì‘...")
            model_start_time = time.time()
            
            # ëª¨ë¸ë³„ ë°ì´í„° ì „ì²˜ë¦¬
            x_tr_processed, x_te_processed = do_preprocessing(
                df_train=x_tr, df_test=x_te, 
                drop_cols=args.drop_cols, encoding_cols=args.encoding_cols, 
                model_name=model_name
            )
            
            # ëª¨ë¸ í•™ìŠµ
            is_model = do_training(df_train=x_tr_processed, df_train_target=y_tr, 
                                 df_test=x_te_processed, df_test_target=y_te, model_name=model_name)
            
            model_time = time.time() - model_start_time
            
            if is_model:
                predictions = is_model.predict_proba(x_te_processed)[:,1]
                successful_models.append(model_name)
                logging.info(f"âœ… {model_name.upper()} ëª¨ë¸ í›ˆë ¨ì´ ëë‚¬ìŠµë‹ˆë‹¤ (ì†Œìš”ì‹œê°„: {model_time:.2f}ì´ˆ)")
            else:
                failed_models.append(model_name)
                logging.info(f"âŒ {model_name.upper()} ëª¨ë¸ í›ˆë ¨ ì‹¤íŒ¨ (ì†Œìš”ì‹œê°„: {model_time:.2f}ì´ˆ)")
                
        except Exception as e:
            model_time = time.time() - model_start_time
            failed_models.append(model_name)
            logging.error(f"âŒ {model_name.upper()} ëª¨ë¸ í›ˆë ¨ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)} (ì†Œìš”ì‹œê°„: {model_time:.2f}ì´ˆ)")
        
        logging.info("-" * 30)
    
    # ì „ì²´ ì‹¤í–‰ ê²°ê³¼ ìš”ì•½
    total_time = time.time() - total_start_time
    logging.info("="*50)
    logging.info("ğŸ‰ ì „ì²´ ëª¨ë¸ ì‹¤í–‰ ì™„ë£Œ!")
    logging.info(f"ì´ ì†Œìš”ì‹œê°„: {total_time:.2f}ì´ˆ")
    logging.info(f"ì„±ê³µí•œ ëª¨ë¸: {len(successful_models)}ê°œ")
    logging.info(f"ì‹¤íŒ¨í•œ ëª¨ë¸: {len(failed_models)}ê°œ")
    
    if successful_models:
        logging.info(f"âœ… ì„±ê³µ ëª¨ë¸ ëª©ë¡: {', '.join([m.upper() for m in successful_models])}")
    
    if failed_models:
        logging.info(f"âŒ ì‹¤íŒ¨ ëª¨ë¸ ëª©ë¡: {', '.join([m.upper() for m in failed_models])}")
    
    logging.info("ğŸ“ ì„±ëŠ¥ ë³´ê³ ì„œëŠ” reports/ í´ë”ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    logging.info("="*50)



if __name__ == "__main__":
    ###############################
    # ì½”ë“œ ì‹¤í–‰ ì˜ì—­ 
    ###############################
    args = argparse.ArgumentParser() # 
    args.add_argument("--path_train", default="./data/hotel_bookings_train.csv", type=str)
    args.add_argument("--path_test", default="./data/hotel_bookings_test.csv", type=str)
    #args.add_argument("--path_submission", default="./data/submission.csv", type=str)
    args.add_argument("--target_name", default="is_canceled", type=str) 
    # eda ë¶„ì„ ê²°ê³¼
    args.add_argument("--drop_cols", default=[
        'deposit_type', 'company' ,'agent','reservation_status', 'reservation_status_date'
        , 'assigned_room_type', 'children', 'babies', 'arrival_date_full'], type=list)
    # args.add_argument("--transform_cols", default=['adr', 'lead_time', 'total_stays'], type=list)
    args.add_argument("--encoding_cols", default=['hotel', 'arrival_date_month', 'meal', 'country', 'market_segment', 'distribution_channel', 'reserved_room_type', 'customer_type', 'market_risk_level'], type=list)


    main(args.parse_args()) 